# ğŸ¯ AI Interview Co-pilot

> Real-time AI-powered interview assistant with live transcription, intelligent question extraction, and context-aware responses.

[English](#english) | [PortuguÃªs](#portuguÃªs)

---

## English

### ğŸŒŸ Overview

AI Interview Co-pilot is an intelligent real-time assistant designed to help you ace technical interviews. It combines live speech-to-text transcription, AI-powered question extraction, and context-aware response generation to provide instant, personalized interview suggestions.

### âœ¨ Key Features

#### ğŸ¨ **Modern UI & UX**
- **âœ¨ NEW: 64px Compact Header**: Elegant gradient design with animated status indicators, model badges, and pill-style buttons
- **ğŸ¯ Enhanced Conversation UI**: Clear visual separation between questions (orange) and answers (blue) with hover effects
- **ğŸ—‘ï¸ Clear Chat Button**: One-click conversation history clearing with confirmation
- **ğŸ“± Responsive Design**: Mobile-optimized header that adapts to smaller screens
- **ğŸ¨ Modern Animations**: Smooth transitions, hover effects, and pulsing status indicators

#### ğŸ¤ **Audio & Transcription**
- **ğŸ¤ Live Transcription**: Real-time speech-to-text using Deepgram Nova-3 API
- **ğŸ™ï¸ Dual Audio Capture**: Simultaneously captures system audio (screen sharing) and microphone with automatic speaker identification
- **ğŸ“± Phone Mode**: Microphone-only capture for phone interviews without screen sharing - toggle to hide preview and expand transcript
- **ğŸ‘¥ Speaker Diarization**: Automatically distinguishes between Interviewer and Candidate voices with color-coded labels (ğŸŸ¥ Red for Interviewer, ğŸŸ© Green for You)
- **ğŸŒ Multi-language Support**: Automatic multi-language detection (English, Portuguese, French, Spanish, German, Hindi, Russian, Japanese, Italian, Dutch)

#### ğŸ¤– **AI Models & Intelligence**
- **ğŸ¤– AI-Powered Responses**: Context-aware answers using GPT-4/GPT-4o-mini or local Ollama models
- **ğŸ  Local LLM Support**: Run completely offline with Ollama (Gemma, Llama, Mistral models)
- **ğŸ® Playground Mode**: Side-by-side model comparison (OpenAI vs Ollama) with real-time performance metrics
- **âš¡ FAQ Cache System**: Instant responses (<50ms) for frequently asked questions with smart matching
- **ğŸ§  Smart Question Extraction**: Automatically extracts clean questions from long, cluttered transcripts
- **ğŸ”„ Real-time Streaming**: WebSocket-based streaming for instant response delivery
- **ğŸ¯ Next Question Predictions**: AI predicts likely next questions based on job requirements and conversation flow
- **ğŸ’¼ Company Questions Generator**: Generate intelligent questions to ask the employer during interviews
- **ğŸŒ Multilingual AI**: Predictions and responses automatically adapt to interview language (EN/FR/PT)

#### ğŸ“Š **Analytics & Management**
- **ğŸ“Š Dashboard Analytics**: Interactive charts (activity, languages, questions, model performance) with 7-day history
- **ğŸ“… Google Calendar Integration**: Color-coded calendar with automatic interview detection (60-day range)
- **âš™ï¸ Settings Management**: Browser-based configuration with visual feedback and model switching
- **ğŸ“ AI Resume Builder**: Drag & drop upload with AI-powered summaries and version history

#### ğŸ› ï¸ **Developer Features**
- **ğŸ–¥ï¸ Electron Overlay**: Transparent, always-on-top overlay window for seamless interview experience
- **ğŸ“„ Resume Analysis**: Detailed CV parsing and summarization for personalized responses
- **ğŸ¨ Modern UI**: Clean, responsive interface with live transcript mirroring
- **ğŸ” Secure Storage**: API keys stored in browser localStorage (never committed to git)

### ğŸ†• Recent Updates (v2.3)

**NEW: Phone Mode for Microphone-Only Interviews (v2.3):**
- ğŸ“± **Phone Toggle**: New "ğŸ“± Telefone" toggle switch in Live Transcript section
- ğŸ¤ **Microphone-Only Capture**: Activate phone mode to capture audio without screen sharing
- ğŸ“ **Dynamic Layout**: Screen Preview hides and Live Transcript expands to full height automatically
- âš¡ **One-Click Activation**: Toggle ON to start microphone capture, OFF to stop
- ğŸ”„ **Independent Mode**: Works separately from dual audio mode (screen + microphone)
- ğŸ“± **Perfect for Phone Calls**: Ideal for traditional phone interviews without video/screen sharing
- ğŸ¨ **Seamless Integration**: All AI features (question extraction, responses, predictions) work in phone mode

**Intelligent Question Prediction System (v2.2):**
- ğŸ¯ **Predictions Toggle**: User-controlled toggle to enable/disable Next Question Predictions (ON by default)
- ğŸŒ **Multilingual Predictions**: Questions automatically generated in the same language as your interview conversation
  - Supports Portuguese, French, and English
  - Automatic language detection from transcription
  - 50+ keyword translations per language for accurate predictions
- ğŸ§  **Smart QuestionPredictor**: AI-powered system that analyzes job requirements and predicts next likely questions
  - Extracts technical skills from job description (Python, SQL, ETL, Spark, AWS, etc.)
  - Analyzes answer depth to determine question type (follow-up vs. related topic)
  - Confidence scoring system (60%-90%) based on relevance
  - Prioritizes uncovered job requirements
- ğŸ’¼ **Company Questions Generator**: Generate intelligent questions to ask the employer
  - 2 General + 3 Technical + 2 Fit & Culture questions
  - Based on job description context
  - Click-to-send functionality for seamless use
  - Multilingual generation matching job description language

**FAQ Knowledge Base Enhancements (v2.1):**
- ğŸ§  **Compact FAQ Card**: Moved to bottom of dashboard, 70% smaller footprint with horizontal inline stats
- ğŸ“– **Interactive FAQ Viewer**: Browse all FAQ questions with accordion-style expandable Q&A items
- ğŸ” **Real-time Search**: Filter FAQ questions and answers as you type
- ğŸŒ **Bilingual Support**: 200-question bilingual FAQ (100 EN + 100 FR) for multilingual interviews
- ğŸ“Š **Extended Coverage**: 100 questions covering SQL, Data Engineering, Databricks, Snowflake, Power BI, Data Lakes
- ğŸ¨ **Modern Design**: Purple gradient header, smooth animations, responsive mobile layout
- âš¡ **Performance**: Client-side caching for instant loading, XSS protection for security

**Major UI/UX Overhaul (v2.0):**
- âœ¨ **Modern 64px Compact Header**: New elegant design with gradient background, rounded corners, and soft shadows
  - Left: Animated status dot (green = ready, red = recording), model badge with gradient, date display
  - Center: Interview title/subtitle with ellipsis overflow
  - Right: Timer with icon, pill-style action buttons (Overlay, Iniciar/Parar)
  - 50% less vertical space, 100% more elegant

- ğŸ¨ **Enhanced Conversation Interface**:
  - Clear button (ğŸ—‘ï¸) with confirmation dialog
  - Distinct color-coded borders: Questions (orange, 4px left border), Answers (blue, 4px left border)
  - Hover effects with elevation animation
  - Better spacing (20px between messages) and shadows

- ğŸ® **New Playground Page**: Compare LLM responses side-by-side
  - OpenAI vs Ollama head-to-head comparison
  - Real-time response streaming
  - Performance metrics (response time, tokens)
  - Easy provider/model switching

- âš™ï¸ **Settings Page Enhancements**:
  - Visual feedback (green borders on save)
  - Model switching with instant badge updates
  - Ollama connection checker
  - Modern toggle design

- ğŸ“Š **Dashboard Improvements**:
  - Session tracking with localStorage persistence
  - Interview details visualization
  - Compact calendar integration
  - FAQ statistics

**Performance & Technical:**
- SPA-aware event handlers for seamless navigation
- Dynamic model badge updates (blue for OpenAI, green for Ollama)
- Status indicator state management (READY â†’ RECORDING)
- Improved error handling and logging
- CSS organization with clear commented sections

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI Interview Co-pilot                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Electron Overlayâ”‚
â”‚   (Port 8004)    â”‚          â”‚  (Transparent)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚     WebSocket (Broadcast)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Django Channels          â”‚
         â”‚    (WebSocket Consumer)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Question Extraction        â”‚
         â”‚  (GPT-3.5-turbo)           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Response Generation        â”‚
         â”‚  (GPT-4/GPT-4o)            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Data Flow

```
1. ğŸ¤ User speaks during interview
   â†“
2. ğŸ”Š Browser captures audio (MediaRecorder API)
   â†“
3. ğŸ“¡ Audio sent to Deepgram Nova-3 API
   â†“
4. ğŸ“ Live transcript generated (interim + final)
   â†“
5. ğŸ”„ Transcript broadcast via WebSocket to:
   - Web interface (display)
   - Electron overlay (mirror display)
   â†“
6. âœ… User presses ENTER to submit question
   â†“
7. ğŸ§¹ GPT-3.5-turbo extracts clean question(s)
   â†“
8. ğŸ“„ Full transcript sent to conversation history
   â†“
9. ğŸ¤– GPT-4/GPT-4o generates context-aware response
   â†“
10. ğŸ’¬ Response streamed back in real-time
```

### ğŸ“¦ Technology Stack

**Backend:**
- Django 5.1.2
- Django Channels 4.1.0 (WebSocket support)
- Daphne 4.1.2 (ASGI server)
- OpenAI API (GPT-4, GPT-4o, GPT-4o-mini, GPT-3.5-turbo)
- Ollama (Local LLM support - llama3.2, qwen2.5, deepseek-r1, etc.)
- Deepgram Nova-3 API (Speech-to-Text)
- PyPDF2 (Resume parsing)

**Frontend:**
- HTML5 / CSS3
- Vanilla JavaScript
- MediaRecorder API
- WebSocket API
- Marked.js (Markdown rendering)

**Desktop:**
- Electron (Transparent overlay window)
- IPC (Inter-Process Communication)

### ğŸ“ Project Structure

```
ai-interview-copilot/
â”œâ”€â”€ copilot/                    # Main Django app
â”‚   â”œâ”€â”€ consumers.py           # WebSocket consumer (live transcription broadcast, language detection)
â”‚   â”œâ”€â”€ pattern_analyzer.py    # QuestionPredictor (intelligent question prediction system)
â”‚   â”œâ”€â”€ utils.py               # Helper functions (question extraction, response generation, FAQ cache)
â”‚   â”œâ”€â”€ views.py               # HTTP views (summaries, calendar, FAQ upload, company questions)
â”‚   â””â”€â”€ urls.py                # URL routing
â”œâ”€â”€ electron/                   # Electron overlay app
â”‚   â”œâ”€â”€ main.js                # Electron main process
â”‚   â”œâ”€â”€ index.html             # Overlay UI
â”‚   â”œâ”€â”€ css/style.css          # Overlay styles
â”‚   â””â”€â”€ js/renderer.js         # Renderer process
â”œâ”€â”€ static/copilot/            # Static files
â”‚   â”œâ”€â”€ css/style.css          # Web interface styles (modern 64px header, conversation UI)
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â”œâ”€â”€ interview.js       # Interview page logic (dual audio, transcription, WebSocket)
â”‚   â”‚   â”œâ”€â”€ dashboard.js       # Dashboard analytics (charts, metrics, session tracking)
â”‚   â”‚   â”œâ”€â”€ resume-builder.js  # Resume upload & AI summaries
â”‚   â”‚   â”œâ”€â”€ playground.js      # Model comparison (OpenAI vs Ollama)
â”‚   â”‚   â”œâ”€â”€ settings.js        # Settings management (API keys, model selection)
â”‚   â”‚   â”œâ”€â”€ calendar.js        # Google Calendar integration
â”‚   â”‚   â””â”€â”€ navigation.js      # SPA navigation system
â”‚   â””â”€â”€ images/                # Assets
â”œâ”€â”€ templates/                  # Django templates
â”‚   â””â”€â”€ index.html             # Main SPA (all pages in one file)
â”œâ”€â”€ resume/                     # Resume PDFs (gitignored)
â”œâ”€â”€ job_description/           # Job description files (gitignored)
â”‚   â””â”€â”€ job_description.txt    # Processed job description text
â”œâ”€â”€ interview_copilot/         # Django project settings
â”‚   â”œâ”€â”€ settings.py            # Project configuration
â”‚   â”œâ”€â”€ asgi.py                # ASGI configuration (Daphne)
â”‚   â””â”€â”€ routing.py             # WebSocket routing
â”œâ”€â”€ faq_data_eng.json          # Original FAQ knowledge base (20 questions)
â”œâ”€â”€ faq_data_eng_extended.json # Extended FAQ (100 questions - English only)
â”œâ”€â”€ faq_data_bilingual.json    # Bilingual FAQ (200 questions - EN/FR)
â”œâ”€â”€ start_server.bat           # Simple Windows startup script
â”œâ”€â”€ start_advanced.bat         # Advanced Windows control panel
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ OLLAMA_SETUP.md           # Complete Ollama installation guide
â”œâ”€â”€ TEST_OLLAMA_INTEGRATION.md # Ollama integration testing guide
â”œâ”€â”€ manage.py                  # Django management script
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

### ğŸš€ Installation

#### Prerequisites

- Python 3.10+
- Node.js 16+ (for Electron)
- npm or yarn
- OpenAI API key
- Deepgram API key ($200 free credits, 750 hours of transcription)

#### Step 1: Clone the Repository

```bash
git clone https://github.com/maikonrenner/InterviewCo-pilot.git
cd InterviewCo-pilot
```

#### Step 2: Set Up Python Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install --upgrade openai
```

#### Step 3: Configure Environment Variables

Create a `.env` file in the `interview_copilot/` directory:

```env
# LLM Provider Configuration
LLM_PROVIDER=openai  # Options: 'openai' or 'ollama'

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (if using local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2  # Options: llama3.2, qwen2.5:14b, deepseek-r1:14b, etc.

# Deepgram Configuration
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# Django Settings
SECRET_KEY=your_django_secret_key_here
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
```

**Get API Keys:**
- OpenAI: [https://platform.openai.com/signup/](https://platform.openai.com/signup/) ([Tutorial](https://youtu.be/OB99E7Y1cMA?si=uEbJeVK5w8UYrHlw))
- Deepgram: [https://console.deepgram.com/signup](https://console.deepgram.com/signup) (Free $200 credits)
- Ollama Setup: See [OLLAMA_SETUP.md](OLLAMA_SETUP.md) for complete installation guide

#### Step 4: Set Up Resume and Job Description

1. Create directories for your documents:
```bash
mkdir resume
mkdir job_description
```

2. Add your resume PDF to `resume/` folder
3. Add job description PDF to `job_description/` folder

#### Step 5: Run Django Server

**Option A: Using Batch Script (Windows - Recommended):**

1. **Simple Startup** - Double-click `start_server.bat`:
   - Activates virtual environment automatically
   - Applies migrations
   - Prompts for port number (default: 8004)
   - Starts server

2. **Advanced Control Panel** - Double-click `start_advanced.bat`:
   - Interactive menu with 6 options:
     - ğŸš€ Start Server (Custom Port)
     - âš¡ Quick Start (Port 8004)
     - ğŸ”„ Apply Migrations Only
     - ğŸ§¹ Clear Cache + Restart
     - ğŸ“¦ Install/Update Dependencies
     - âŒ Exit
   - Color-coded UI with professional interface

**Option B: Manual Command Line:**

```bash
# Activate virtual environment (Windows)
venv\Scripts\activate

# Apply migrations
python manage.py migrate

# Run server on port 8004
python manage.py runserver 8004
```

#### Step 6: Set Up Electron Overlay (Optional)

```bash
cd electron
npm install
npm start
```

### ğŸ’» Usage

#### Web Interface

1. Open browser: `http://localhost:8004`
2. Click **"ğŸ™ï¸ Iniciar Entrevista"** to begin dual audio capture
3. Allow screen sharing and microphone permissions when prompted
4. The system will capture both:
   - **System audio** (from screen sharing) â†’ Labeled as **[Interviewer]** (red)
   - **Microphone audio** â†’ Labeled as **[You]** (green)
5. Speak during the interview - live transcription with speaker labels appears
6. Press **ENTER** to send the transcript and get AI response
7. Click **"Open Overlay"** to launch Electron window (optional)
8. Click **"â¹ï¸ Parar Entrevista"** to stop the interview

#### Electron Overlay

1. Launch automatically from web interface OR run manually:
```bash
cd electron
npm start
```

2. Position the overlay window on your screen
3. Adjust opacity using slider (10% - 100%)
4. Live transcript mirrors from web interface
5. Press **ENTER** to send question to AI
6. View clean question + AI response in conversation area

### ğŸ”§ Configuration

#### Change AI Models

Edit `static/copilot/js/interview.js`:

```javascript
// Line 103: Default model for responses
model: 'gpt-4o' // Options: 'gpt-4', 'gpt-4o'
```

#### Adjust Response Length

Edit `copilot/utils.py`:

```python
# Line 290: Resume summary tokens
max_tokens=3000

# Line 567: AI response tokens (OpenAI)
max_tokens=450

# Line 626: AI response tokens (Ollama)
'num_predict': 450
```

#### Switch Between OpenAI and Ollama

Edit `interview_copilot/.env`:

```env
# Use OpenAI (cloud)
LLM_PROVIDER=openai

# OR use Ollama (local)
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2
```

#### Customize System Prompt

Edit `copilot/utils.py` starting at line 525 to modify the AI persona and response format. The current prompt is optimized for concise, context-aware responses (2-4 sentences, 450 tokens max).

### ğŸ§ª Key Features Explained

#### 1. Dual Audio Capture with Speaker Diarization

The system simultaneously captures audio from two sources and automatically identifies speakers:

**Audio Sources:**
- **Screen Sharing Audio**: Captures the interviewer's voice from virtual meeting platforms (Zoom, Teams, Google Meet)
- **Microphone Audio**: Captures your voice (candidate) directly from your microphone

**How It Works:**
```
1. User clicks "ğŸ™ï¸ Iniciar Entrevista"
   â†“
2. Browser requests two permissions:
   - Screen sharing with audio (getDisplayMedia)
   - Microphone access (getUserMedia)
   â†“
3. Web Audio API combines both streams into one
   â†“
4. Combined audio sent to Deepgram with diarization enabled
   â†“
5. Deepgram identifies speakers (Speaker 0, Speaker 1)
   â†“
6. System maps speakers to roles:
   - First speaker (usually from screen) â†’ [Interviewer] (red label)
   - Second speaker (usually from mic) â†’ [You] (green label)
   â†“
7. Live transcript shows color-coded speaker labels
```

**Visual Indicators:**
- ğŸŸ¥ **[Interviewer]**: Red background - Questions from the interviewer
- ğŸŸ© **[You]**: Green background - Your responses

This feature is perfect for virtual interviews where you need to capture both sides of the conversation accurately.

#### 1.5. Phone Mode (ğŸ“±)

For phone-only interviews where screen sharing isn't needed:

**How It Works:**
```
1. User activates "ğŸ“± Telefone" toggle in Live Transcript section
   â†“
2. System automatically:
   - Hides Screen Preview container
   - Expands Live Transcript to full height (100%)
   - Starts microphone capture
   â†“
3. Microphone captures candidate's voice
   â†“
4. Audio sent to Deepgram for real-time transcription
   â†“
5. Transcription displayed in expanded view
   â†“
6. User deactivates toggle to stop:
   - Screen Preview reappears
   - Live Transcript returns to normal size
   - Microphone capture stops
```

**Key Benefits:**
- âœ… **Maximized Screen Space**: Full transcript view without screen preview
- âœ… **Phone Interview Optimized**: Perfect for phone calls without screen sharing
- âœ… **Independent Mode**: Separate from dual audio capture (screen + mic)
- âœ… **One-Click Toggle**: Easy activation/deactivation
- âœ… **Seamless Integration**: Works with all existing features (AI responses, question extraction, etc.)

**Visual Changes:**
- **Toggle ON**: Screen Preview hidden, Transcript expands upward to fill space
- **Toggle OFF**: Screen Preview visible, Transcript returns to normal layout

This feature is ideal for traditional phone interviews or when you only need to capture your own voice without screen content.

#### 2. Smart Question Extraction

The system uses GPT-3.5-turbo to extract clean questions from potentially long, cluttered transcripts:

**Input (Transcript):**
```
"Insert some duplicate records. Okay, as of now. Insert into EMPL one.
So I'll take a EMPL one, and I will try to insert some duplicate records.
So I will insert the duplicate records. Okay? And let us try to see,
how actually we can solve the next question..."
```

**Output (Extracted):**
```
"How do you find duplicate records in a table?"
```

#### 2. Context-Aware Responses

The AI maintains full conversation history and personalizes responses based on:
- Complete resume summary (2000 tokens)
- Job description context
- Previous conversation turns
- User's technical background

#### 3. Multi-Question Handling

When multiple questions are asked in one transcript, the system:
- Extracts ALL questions while preserving context
- Sends full transcript to LLM for comprehensive understanding
- Displays clean, formatted questions in UI

#### 4. Real-Time Broadcast

Uses Django Channels group messaging to broadcast live transcripts to:
- All connected web clients
- Electron overlay instances
- Maintains synchronization across all interfaces

#### 5. Dashboard Analytics

Track your interview performance with interactive visualizations:
- **Interview Activity Chart**: 7-day history of interview sessions
- **Language Distribution**: Pie chart of languages used in interviews
- **Questions Answered**: Bar chart tracking question count over time
- **AI Model Performance**: Compare response times across different models
- **Session Metrics**: Total interviews, average duration, questions answered, AI response time

All data is stored locally in the browser's localStorage.

#### 6. Google Calendar Integration

Automatically sync interview schedules from Google Calendar:
- **Visual Calendar**: Color-coded day blocks (ğŸŸ© green for upcoming, â¬œ gray for past interviews)
- **Smart Filtering**: Automatically detects interview-related events using multilingual keywords
- **Event Details**: Click on any day to view interview details (time, description, location)
- **60-Day Range**: Shows interviews from 60 days back to 60 days ahead

**Supported Keywords**: interview, entrevista, entretien, meeting, rencontre, discussion, Ã©change, call, appel

#### 7. Settings Management

Configure API keys directly in the browser (no backend required):
- **OpenAI API Key**: Configure your OpenAI key for GPT models
- **Deepgram API Key**: Configure your Deepgram key for speech-to-text
- **Default AI Model**: Select preferred GPT model (GPT-4o, GPT-4o Mini, GPT-4 Turbo, etc.)
- **Auto-Language Detection**: System automatically detects and transcribes multiple languages
- **Local Storage**: All settings stored securely in browser's localStorage

**Visual Feedback**:
- Button changes to "â³ Saving..." â†’ "âœ… Saved!"
- Fields turn green when successfully saved
- Success/error messages with animations

#### 8. AI Resume Builder

Upload and analyze documents with AI-powered summaries:
- **Resume Upload**: Drag & drop or browse for resume files (PDF, DOCX, TXT)
- **Job Description Input**: Paste text or upload file for job descriptions
- **AI Summaries**: GPT-4 generates concise summaries of both documents
- **Interview Details**: Add company name and job title for context
- **Version History**: Track multiple document versions
- **Document Management**: View, delete, and manage uploaded documents

#### 9. FAQ Knowledge Base System

Pre-load frequently asked questions for instant, cost-free responses:

**Core Features:**
- **Auto-Load**: Automatically loads FAQ from JSON files on startup
- **Instant Responses**: Cached answers returned in <50ms (no LLM call needed)
- **Hit Tracking**: Monitors which questions are most frequently asked
- **Cache Management**: Upload new FAQ files via drag-and-drop interface
- **Stats Dashboard**: View FAQ count, last update time, and usage statistics
- **Smart Matching**: Normalizes questions for fuzzy matching (case-insensitive, punctuation-agnostic)

**NEW: FAQ Viewer Interface:**
- **ğŸ“– Browse All Questions**: Click "ğŸ‘ï¸ View" button to open interactive FAQ viewer
- **Accordion UI**: Expandable/collapsible Q&A items for easy browsing
- **ğŸ” Real-time Search**: Filter questions and answers as you type
- **Visual Design**: Purple gradient header with smooth animations
- **Client-side Caching**: Instant loading after first fetch
- **XSS Protection**: HTML escaping for secure content display

**NEW: Bilingual Support:**
- **Extended FAQ**: 100 questions covering SQL, Data Engineering, Databricks, Snowflake, Power BI, Data Lakes
- **Bilingual FAQ**: 200 questions total (100 English + 100 French) for multilingual interviews
- **Professional Translations**: Technical accuracy maintained across languages
- **Sample Files Included**:
  - `faq_data_eng_extended.json`: 100 English questions
  - `faq_data_bilingual.json`: 200 bilingual questions (EN/FR)

**Performance Benefits:**
- âš¡ **100x-500x Faster**: Cache hit (50ms) vs LLM call (2-5 seconds)
- ğŸ’° **Cost Savings**: No API calls for frequently asked questions
- ğŸ“Š **Efficiency Tracking**: Monitor cache hit rate to optimize FAQ coverage

#### 10. Local LLM with Ollama

Run the entire system offline with local models:
- **Privacy-First**: All data stays on your machine
- **Cost-Free**: No API costs after initial setup
- **Fast Inference**: Optimized for M-series Macs and NVIDIA GPUs
- **Model Options**: llama3.2 (fast), qwen2.5:14b (balanced), deepseek-r1:14b (quality)
- **Easy Switch**: Toggle between OpenAI and Ollama in settings
- **Complete Guide**: See [OLLAMA_SETUP.md](OLLAMA_SETUP.md) for installation

#### 11. Playground - Model Comparison

Compare different LLM responses side-by-side in real-time:
- **Dual Panel Interface**: Left panel (LLM 1) vs Right panel (LLM 2)
- **Flexible Selection**: Choose any combination:
  - OpenAI GPT-4o vs Ollama Gemma 3:4b
  - GPT-4o-mini vs GPT-4
  - Llama 3:8b vs Mistral 7b
- **Centralized Question Input**: Ask once, get answers from both models simultaneously
- **Real-time Streaming**: Watch responses generate character-by-character
- **Performance Metrics**: Compare response times and quality
- **Easy Provider Switching**: Toggle between OpenAI and Ollama per panel
- **Perfect for**: Testing prompts, evaluating models, choosing the best LLM for your needs

**How to Access**: Click "ğŸ® Playground" in the sidebar navigation

#### 12. Modern Header Design

The new 64px compact header provides maximum screen space while maintaining full functionality:
- **Animated Status Indicator**: Pulsing green dot (READY) â†’ Solid red dot (RECORDING)
- **Dynamic Model Badge**:
  - Blue gradient for OpenAI models (ğŸ¤–)
  - Green gradient for Ollama models (ğŸ¦™)
  - Auto-updates when switching in Settings
- **Timer Display**: Gray background box with icon (â±) and tabular numbers
- **Pill-Style Buttons**:
  - Purple gradient "Overlay" button
  - Green gradient "Iniciar" button (changes to red "Parar" when recording)
  - Smooth hover effects with elevation
- **Responsive Behavior**: On screens <1024px:
  - Date hidden
  - Button text hidden (icons only)
  - Reduced spacing
  - Maintains 64px height

#### 13. Enhanced Conversation UI

Improved visual organization for better readability:
- **Clear Button**: Red "ğŸ—‘ï¸ Clear" button in conversation header
  - Confirmation dialog before clearing
  - Preserves conversation system message
- **Color-Coded Messages**:
  - ğŸŸ§ **Questions**: Orange background (#fff3e0) with orange left border (#ff9800)
  - ğŸ”µ **Answers**: Blue background (#e3f2fd) with blue left border (#2196F3)
- **Interactive Elements**:
  - Hover: Messages elevate with shadow increase
  - Smooth transitions (0.3s)
  - Rounded corners (10px)
- **Better Spacing**: 20px between messages (was 15px)
- **Shadows**: Subtle depth with layered shadows

#### 14. Next Question Predictions (ğŸ¯)

Intelligent prediction system that anticipates likely interview questions:

**How It Works:**
```
1. Interview question asked and answered
   â†“
2. QuestionPredictor analyzes:
   - Current topic (Python, SQL, ETL, etc.)
   - Answer depth (superficial vs. detailed)
   - Job requirements (extracted from description)
   - Covered vs. uncovered topics
   â†“
3. Language detection from transcription
   - Portuguese: "vocÃª", "qual", "como"
   - French: "vous", "quel", "comment"
   - English: "you", "what", "how"
   â†“
4. Generate 3 predictions with confidence scores
   - Follow-up questions (dig deeper, 85%-90%)
   - Related topics (move to next skill, 75%-88%)
   â†“
5. Translate predictions to detected language
   - "Can you describe" â†’ "Pode descrever" (PT)
   - "What's your experience" â†’ "Quelle est votre expÃ©rience" (FR)
   â†“
6. Display in predictions panel
   - Click to ask automatically
   - Toggle ON/OFF with ğŸ¯ Predictions switch
```

**Features:**
- **Job-Aware**: Prioritizes skills mentioned in job description
- **Context-Sensitive**: Adjusts based on answer quality
- **Multilingual**: Auto-translates to interview language
- **User Control**: Toggle predictions ON/OFF at any time
- **Smart Categorization**: Follow-up vs. related topic questions

**Example (Portuguese Interview):**
```
Question: "Como vocÃª trabalha com Python?"
Answer: [Detailed response about libraries and projects]
Predictions:
  â†’ "Quais bibliotecas Python vocÃª jÃ¡ utilizou?" (85%)
  â†’ "Como vocÃª otimiza cÃ³digo Python?" (83%)
  â†’ "Qual Ã© sua experiÃªncia com SQL?" (80%)
```

#### 15. Company Questions Generator (ğŸ’¼)

Generate strategic questions to ask the employer during interviews:

**How It Works:**
```
1. Click "ğŸ’¼ Questions for Company" button
   â†“
2. System reads job description
   â†“
3. Detects language (English/French/Portuguese)
   â†“
4. GPT-4o-mini generates categorized questions:
   - 2 General (company overview, role expectations)
   - 3 Technical (tools, methodologies, challenges)
   - 2 Fit & Culture (team dynamics, growth opportunities)
   â†“
5. Display in panel with color-coded categories:
   - ğŸŒ General (blue)
   - âš™ï¸ Technical (purple)
   - ğŸ¤ Fit & Culture (green)
   â†“
6. Click any question to send automatically
```

**Benefits:**
- Shows genuine interest in the role
- Demonstrates understanding of technical requirements
- Helps evaluate company fit
- Questions adapt to job description specifics
- Multilingual support (EN/FR/PT)

**Example Questions:**
```
ğŸŒ General:
- What are the key success metrics for this role in the first 90 days?
- How does this position contribute to the company's strategic goals?

âš™ï¸ Technical:
- What data stack and tools does the team currently use?
- How do you approach data quality and governance?
- What are the biggest data engineering challenges the team is facing?

ğŸ¤ Fit & Culture:
- How does the team collaborate on cross-functional projects?
- What opportunities exist for professional development and learning?
```

### ğŸ” Security Notes

- **Never commit** `.env` files with API keys
- **Never commit** resume/job description PDFs (contains personal data)
- Use environment variables for all sensitive configuration
- `.gitignore` is configured to exclude sensitive files

### ğŸ› Troubleshooting

#### WebSocket Connection Issues

```python
# Check if channel layer is configured in settings.py
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels.layers.InMemoryChannelLayer'
    }
}
```

#### Electron Won't Launch

```bash
# Reinstall Electron dependencies
cd electron
rm -rf node_modules
npm install
npm start
```

#### Audio Capture Not Working

- Ensure browser permissions are granted
- Use HTTPS or localhost (required for MediaRecorder API)
- Check browser console for errors

### ğŸ“ License

MIT License - feel free to use this project for personal or commercial purposes.

### ğŸ‘¨â€ğŸ’» Author

**Maikon Renner**
- GitHub: [@maikonrenner](https://github.com/maikonrenner)
- Project: [InterviewCo-pilot](https://github.com/maikonrenner/InterviewCo-pilot)

### â­ Support

If you find this project helpful, please consider giving it a star on GitHub!

---

## PortuguÃªs

### ğŸŒŸ VisÃ£o Geral

AI Interview Co-pilot Ã© um assistente inteligente em tempo real projetado para ajudÃ¡-lo a ter sucesso em entrevistas tÃ©cnicas. Ele combina transcriÃ§Ã£o de fala para texto ao vivo, extraÃ§Ã£o de perguntas com IA e geraÃ§Ã£o de respostas conscientes do contexto para fornecer sugestÃµes instantÃ¢neas e personalizadas.

### âœ¨ Recursos Principais

- **ğŸ¤ TranscriÃ§Ã£o ao Vivo**: ConversÃ£o de fala em texto em tempo real usando Deepgram Nova-3 API
- **ğŸ™ï¸ Captura Dupla de Ãudio**: Captura simultaneamente Ã¡udio do sistema (compartilhamento de tela) e microfone com identificaÃ§Ã£o automÃ¡tica de locutores
- **ğŸ“± Modo Telefone**: Captura apenas do microfone para entrevistas telefÃ´nicas sem compartilhamento de tela - toggle para ocultar preview e expandir transcriÃ§Ã£o
- **ğŸ‘¥ DiarizaÃ§Ã£o de Locutores**: Distingue automaticamente entre Entrevistador e Candidato com etiquetas coloridas
- **ğŸ–¥ï¸ Overlay Electron**: Janela transparente sempre visÃ­vel para experiÃªncia de entrevista perfeita
- **ğŸ¤– Respostas com IA**: Respostas conscientes do contexto usando modelos GPT-4/GPT-4o
- **ğŸ§  ExtraÃ§Ã£o Inteligente de Perguntas**: Extrai automaticamente perguntas limpas de transcriÃ§Ãµes longas e poluÃ­das
- **ğŸ“„ AnÃ¡lise de CurrÃ­culo**: AnÃ¡lise detalhada e resumo do CV para respostas personalizadas
- **ğŸŒ Suporte Multi-idioma**: DetecÃ§Ã£o automÃ¡tica de mÃºltiplos idiomas (inglÃªs, portuguÃªs, francÃªs, espanhol, alemÃ£o, etc.)
- **ğŸ”„ Streaming em Tempo Real**: Entrega instantÃ¢nea de respostas via WebSocket
- **ğŸ¨ Interface Moderna**: Interface limpa e responsiva com espelhamento de transcriÃ§Ã£o ao vivo
- **ğŸ“Š Dashboard Analytics**: GrÃ¡ficos interativos e mÃ©tricas para acompanhar desempenho em entrevistas
- **ğŸ“… IntegraÃ§Ã£o com Google Calendar**: Sincronize e visualize entrevistas futuras/passadas do Google Calendar
- **âš™ï¸ Gerenciamento de ConfiguraÃ§Ãµes**: ConfiguraÃ§Ã£o de chaves de API (OpenAI e Deepgram) no navegador
- **ğŸ“ AI Resume Builder**: Upload e anÃ¡lise de currÃ­culos/descriÃ§Ãµes de vaga com resumos gerados por IA

### ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI Interview Co-pilot                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Interface Web   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Overlay Electronâ”‚
â”‚   (Porta 8004)   â”‚          â”‚  (Transparente)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚     WebSocket (Broadcast)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Django Channels          â”‚
         â”‚    (WebSocket Consumer)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ExtraÃ§Ã£o de Perguntas      â”‚
         â”‚  (GPT-3.5-turbo)           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  GeraÃ§Ã£o de Respostas       â”‚
         â”‚  (GPT-4/GPT-4o)            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Fluxo de Dados

```
1. ğŸ¤ UsuÃ¡rio fala durante a entrevista
   â†“
2. ğŸ”Š Navegador captura Ã¡udio (MediaRecorder API)
   â†“
3. ğŸ“¡ Ãudio enviado para Deepgram Nova-3 API
   â†“
4. ğŸ“ TranscriÃ§Ã£o ao vivo gerada (interim + final)
   â†“
5. ğŸ”„ TranscriÃ§Ã£o transmitida via WebSocket para:
   - Interface web (exibiÃ§Ã£o)
   - Overlay Electron (exibiÃ§Ã£o espelhada)
   â†“
6. âœ… UsuÃ¡rio pressiona ENTER para enviar pergunta
   â†“
7. ğŸ§¹ GPT-3.5-turbo extrai pergunta(s) limpa(s)
   â†“
8. ğŸ“„ TranscriÃ§Ã£o completa enviada ao histÃ³rico de conversa
   â†“
9. ğŸ¤– GPT-4/GPT-4o gera resposta consciente do contexto
   â†“
10. ğŸ’¬ Resposta transmitida de volta em tempo real
```

### ğŸ“¦ Stack TecnolÃ³gico

**Backend:**
- Django 5.1.2
- Django Channels 4.1.0 (suporte WebSocket)
- Daphne 4.1.2 (servidor ASGI)
- OpenAI API (GPT-4, GPT-4o, GPT-3.5-turbo)
- Deepgram Nova-3 API (Speech-to-Text)
- PyPDF2 (anÃ¡lise de currÃ­culo)

**Frontend:**
- HTML5 / CSS3
- JavaScript Vanilla
- MediaRecorder API
- WebSocket API
- Marked.js (renderizaÃ§Ã£o Markdown)

**Desktop:**
- Electron (janela overlay transparente)
- IPC (comunicaÃ§Ã£o entre processos)

### ğŸš€ InstalaÃ§Ã£o

#### PrÃ©-requisitos

- Python 3.10+
- Node.js 16+ (para Electron)
- npm ou yarn
- Chave API OpenAI
- Chave API Deepgram (crÃ©ditos grÃ¡tis de $200, 750 horas de transcriÃ§Ã£o)

#### Passo 1: Clonar o RepositÃ³rio

```bash
git clone https://github.com/maikonrenner/InterviewCo-pilot.git
cd InterviewCo-pilot
```

#### Passo 2: Configurar Ambiente Python

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
pip install --upgrade openai
```

#### Passo 3: Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` no diretÃ³rio `interview_copilot/`:

```env
# ConfiguraÃ§Ã£o OpenAI
OPENAI_API_KEY=sua_chave_api_openai_aqui

# ConfiguraÃ§Ã£o Deepgram
DEEPGRAM_API_KEY=sua_chave_api_deepgram_aqui

# ConfiguraÃ§Ãµes Django
SECRET_KEY=sua_chave_secreta_django_aqui
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
```

**Obter Chaves de API:**
- OpenAI: [https://platform.openai.com/signup/](https://platform.openai.com/signup/) ([Tutorial](https://youtu.be/OB99E7Y1cMA?si=uEbJeVK5w8UYrHlw))
- Deepgram: [https://console.deepgram.com/signup](https://console.deepgram.com/signup) (CrÃ©ditos grÃ¡tis de $200)

#### Passo 4: Configurar CurrÃ­culo e DescriÃ§Ã£o da Vaga

1. Criar diretÃ³rios para seus documentos:
```bash
mkdir resume
mkdir job_description
```

2. Adicionar seu currÃ­culo em PDF na pasta `resume/`
3. Adicionar descriÃ§Ã£o da vaga em PDF na pasta `job_description/`

#### Passo 5: Executar Servidor Django

```bash
# Aplicar migraÃ§Ãµes
python manage.py migrate

# Executar servidor na porta 8004
python manage.py runserver 8004
```

#### Passo 6: Configurar Overlay Electron (Opcional)

```bash
cd electron
npm install
npm start
```

### ğŸ’» Uso

#### Interface Web

1. Abrir navegador: `http://localhost:8004`
2. Clicar em **"ğŸ™ï¸ Iniciar Entrevista"** para iniciar captura dupla de Ã¡udio
3. Permitir permissÃµes de compartilhamento de tela e microfone quando solicitado
4. O sistema irÃ¡ capturar ambos:
   - **Ãudio do sistema** (do compartilhamento de tela) â†’ Rotulado como **[Interviewer]** (vermelho)
   - **Ãudio do microfone** â†’ Rotulado como **[You]** (verde)
5. Fale durante a entrevista - transcriÃ§Ã£o ao vivo com etiquetas de locutor aparece
6. Pressionar **ENTER** para enviar a transcriÃ§Ã£o e obter resposta da IA
7. Clicar em **"Open Overlay"** para abrir janela Electron (opcional)
8. Clicar em **"â¹ï¸ Parar Entrevista"** para parar a entrevista

#### Overlay Electron

1. Iniciar automaticamente da interface web OU executar manualmente:
```bash
cd electron
npm start
```

2. Posicionar a janela overlay na tela
3. Ajustar opacidade usando o controle deslizante (10% - 100%)
4. TranscriÃ§Ã£o ao vivo espelhada da interface web
5. Pressionar **ENTER** para enviar pergunta Ã  IA
6. Ver pergunta limpa + resposta da IA na Ã¡rea de conversa

### ğŸ§ª Recursos Principais Explicados

#### 1. Captura Dupla de Ãudio com DiarizaÃ§Ã£o de Locutores

O sistema captura simultaneamente Ã¡udio de duas fontes e identifica automaticamente os locutores:

**Fontes de Ãudio:**
- **Ãudio do Compartilhamento de Tela**: Captura a voz do entrevistador de plataformas de reuniÃ£o virtual (Zoom, Teams, Google Meet)
- **Ãudio do Microfone**: Captura sua voz (candidato) diretamente do seu microfone

**Como Funciona:**
```
1. UsuÃ¡rio clica em "ğŸ™ï¸ Iniciar Entrevista"
   â†“
2. Navegador solicita duas permissÃµes:
   - Compartilhamento de tela com Ã¡udio (getDisplayMedia)
   - Acesso ao microfone (getUserMedia)
   â†“
3. Web Audio API combina ambos os streams em um
   â†“
4. Ãudio combinado enviado ao Deepgram com diarizaÃ§Ã£o habilitada
   â†“
5. Deepgram identifica locutores (Speaker 0, Speaker 1)
   â†“
6. Sistema mapeia locutores para funÃ§Ãµes:
   - Primeiro locutor (geralmente da tela) â†’ [Interviewer] (etiqueta vermelha)
   - Segundo locutor (geralmente do mic) â†’ [You] (etiqueta verde)
   â†“
7. TranscriÃ§Ã£o ao vivo mostra etiquetas coloridas de locutores
```

**Indicadores Visuais:**
- ğŸŸ¥ **[Interviewer]**: Fundo vermelho - Perguntas do entrevistador
- ğŸŸ© **[You]**: Fundo verde - Suas respostas

Este recurso Ã© perfeito para entrevistas virtuais onde vocÃª precisa capturar ambos os lados da conversa com precisÃ£o.

#### 2. ExtraÃ§Ã£o Inteligente de Perguntas

O sistema usa GPT-3.5-turbo para extrair perguntas limpas de transcriÃ§Ãµes potencialmente longas e confusas:

**Entrada (TranscriÃ§Ã£o):**
```
"Insert some duplicate records. Okay, as of now. Insert into EMPL one.
So I'll take a EMPL one, and I will try to insert some duplicate records.
So I will insert the duplicate records. Okay? And let us try to see,
how actually we can solve the next question..."
```

**SaÃ­da (ExtraÃ­da):**
```
"Como encontrar registros duplicados em uma tabela?"
```

#### 2. Respostas Conscientes do Contexto

A IA mantÃ©m histÃ³rico completo da conversa e personaliza respostas baseadas em:
- Resumo completo do currÃ­culo (2000 tokens)
- Contexto da descriÃ§Ã£o da vaga
- Turnos anteriores da conversa
- Background tÃ©cnico do usuÃ¡rio

#### 3. Tratamento de MÃºltiplas Perguntas

Quando mÃºltiplas perguntas sÃ£o feitas em uma transcriÃ§Ã£o, o sistema:
- Extrai TODAS as perguntas preservando o contexto
- Envia transcriÃ§Ã£o completa ao LLM para compreensÃ£o abrangente
- Exibe perguntas limpas e formatadas na UI

#### 4. Broadcast em Tempo Real

Usa mensagens de grupo do Django Channels para transmitir transcriÃ§Ãµes ao vivo para:
- Todos os clientes web conectados
- InstÃ¢ncias do overlay Electron
- MantÃ©m sincronizaÃ§Ã£o entre todas as interfaces

#### 5. Dashboard Analytics

Acompanhe seu desempenho em entrevistas com visualizaÃ§Ãµes interativas:
- **GrÃ¡fico de Atividade**: HistÃ³rico de 7 dias de sessÃµes de entrevista
- **DistribuiÃ§Ã£o de Idiomas**: GrÃ¡fico de pizza dos idiomas usados
- **Perguntas Respondidas**: GrÃ¡fico de barras rastreando quantidade de perguntas ao longo do tempo
- **Desempenho dos Modelos AI**: Compare tempos de resposta entre diferentes modelos
- **MÃ©tricas de SessÃ£o**: Total de entrevistas, duraÃ§Ã£o mÃ©dia, perguntas respondidas, tempo de resposta da IA

Todos os dados sÃ£o armazenados localmente no localStorage do navegador.

#### 6. IntegraÃ§Ã£o com Google Calendar

Sincronize automaticamente agendamentos de entrevistas do Google Calendar:
- **CalendÃ¡rio Visual**: Blocos de dias com cÃ³digo de cores (ğŸŸ© verde para futuras, â¬œ cinza para passadas)
- **Filtragem Inteligente**: Detecta automaticamente eventos relacionados a entrevistas usando palavras-chave multilÃ­ngues
- **Detalhes do Evento**: Clique em qualquer dia para ver detalhes da entrevista (hora, descriÃ§Ã£o, local)
- **Alcance de 60 Dias**: Mostra entrevistas de 60 dias atrÃ¡s atÃ© 60 dias Ã  frente

**Palavras-chave Suportadas**: interview, entrevista, entretien, meeting, rencontre, discussion, Ã©change, call, appel

#### 7. Gerenciamento de ConfiguraÃ§Ãµes

Configure chaves de API diretamente no navegador (sem necessidade de backend):
- **Chave API OpenAI**: Configure sua chave OpenAI para modelos GPT
- **Chave API Deepgram**: Configure sua chave Deepgram para conversÃ£o de fala em texto
- **Modelo AI PadrÃ£o**: Selecione o modelo GPT preferido (GPT-4o, GPT-4o Mini, GPT-4 Turbo, etc.)
- **DetecÃ§Ã£o AutomÃ¡tica de Idioma**: Sistema detecta e transcreve automaticamente mÃºltiplos idiomas
- **Armazenamento Local**: Todas as configuraÃ§Ãµes armazenadas com seguranÃ§a no localStorage do navegador

**Feedback Visual**:
- BotÃ£o muda para "â³ Saving..." â†’ "âœ… Saved!"
- Campos ficam verdes quando salvos com sucesso
- Mensagens de sucesso/erro com animaÃ§Ãµes

#### 8. AI Resume Builder

Upload e anÃ¡lise de documentos com resumos gerados por IA:
- **Upload de CurrÃ­culo**: Arraste e solte ou navegue por arquivos de currÃ­culo (PDF, DOCX, TXT)
- **Entrada de DescriÃ§Ã£o da Vaga**: Cole texto ou faÃ§a upload de arquivo para descriÃ§Ãµes de vaga
- **Resumos AI**: GPT-4 gera resumos concisos de ambos os documentos
- **Detalhes da Entrevista**: Adicione nome da empresa e tÃ­tulo da vaga para contexto
- **HistÃ³rico de VersÃµes**: Rastreie mÃºltiplas versÃµes de documentos
- **Gerenciamento de Documentos**: Visualize, exclua e gerencie documentos enviados

### ğŸ” Notas de SeguranÃ§a

- **Nunca faÃ§a commit** de arquivos `.env` com chaves de API
- **Nunca faÃ§a commit** de PDFs de currÃ­culo/descriÃ§Ã£o de vaga (contÃ©m dados pessoais)
- Use variÃ¡veis de ambiente para todas as configuraÃ§Ãµes sensÃ­veis
- `.gitignore` estÃ¡ configurado para excluir arquivos sensÃ­veis

### ğŸ› SoluÃ§Ã£o de Problemas

#### Problemas de ConexÃ£o WebSocket

```python
# Verifique se a camada de canais estÃ¡ configurada em settings.py
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels.layers.InMemoryChannelLayer'
    }
}
```

#### Electron NÃ£o Inicia

```bash
# Reinstalar dependÃªncias do Electron
cd electron
rm -rf node_modules
npm install
npm start
```

#### Captura de Ãudio NÃ£o Funciona

- Certifique-se de que as permissÃµes do navegador foram concedidas
- Use HTTPS ou localhost (necessÃ¡rio para MediaRecorder API)
- Verifique o console do navegador para erros

### ğŸ“ LicenÃ§a

LicenÃ§a MIT - sinta-se livre para usar este projeto para fins pessoais ou comerciais.

### ğŸ‘¨â€ğŸ’» Autor

**Maikon Renner**
- GitHub: [@maikonrenner](https://github.com/maikonrenner)
- Projeto: [InterviewCo-pilot](https://github.com/maikonrenner/InterviewCo-pilot)

### â­ Apoie

Se vocÃª achar este projeto Ãºtil, considere dar uma estrela no GitHub!

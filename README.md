# ğŸ¯ AI Interview Co-pilot

> Real-time AI-powered interview assistant with live transcription, intelligent question extraction, and context-aware responses.

[English](#english) | [PortuguÃªs](#portuguÃªs)

---

## English

### ğŸŒŸ Overview

AI Interview Co-pilot is an intelligent real-time assistant designed to help you ace technical interviews. It combines live speech-to-text transcription, AI-powered question extraction, and context-aware response generation to provide instant, personalized interview suggestions.

### âœ¨ Key Features

- **ğŸ¤ Live Transcription**: Real-time speech-to-text using Deepgram Nova-3 API
- **ğŸ–¥ï¸ Electron Overlay**: Transparent, always-on-top overlay window for seamless interview experience
- **ğŸ¤– AI-Powered Responses**: Context-aware answers using GPT-4/GPT-4o models
- **ğŸ§  Smart Question Extraction**: Automatically extracts clean questions from long, cluttered transcripts
- **ğŸ“„ Resume Analysis**: Detailed CV parsing and summarization for personalized responses
- **ğŸŒ Multi-language Support**: Supports English, Portuguese, French, Spanish, and German
- **ğŸ”„ Real-time Streaming**: WebSocket-based streaming for instant response delivery
- **ğŸ¨ Modern UI**: Clean, responsive interface with live transcript mirroring

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI Interview Co-pilot                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Electron Overlayâ”‚
â”‚   (Port 8004)    â”‚          â”‚  (Transparent)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚     WebSocket (Broadcast)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Django Channels          â”‚
         â”‚    (WebSocket Consumer)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Question Extraction        â”‚
         â”‚  (GPT-3.5-turbo)           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Response Generation        â”‚
         â”‚  (GPT-4/GPT-4o)            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Data Flow

```
1. ğŸ¤ User speaks during interview
   â†“
2. ğŸ”Š Browser captures audio (MediaRecorder API)
   â†“
3. ğŸ“¡ Audio sent to Deepgram Nova-3 API
   â†“
4. ğŸ“ Live transcript generated (interim + final)
   â†“
5. ğŸ”„ Transcript broadcast via WebSocket to:
   - Web interface (display)
   - Electron overlay (mirror display)
   â†“
6. âœ… User presses ENTER to submit question
   â†“
7. ğŸ§¹ GPT-3.5-turbo extracts clean question(s)
   â†“
8. ğŸ“„ Full transcript sent to conversation history
   â†“
9. ğŸ¤– GPT-4/GPT-4o generates context-aware response
   â†“
10. ğŸ’¬ Response streamed back in real-time
```

### ğŸ“¦ Technology Stack

**Backend:**
- Django 5.1.2
- Django Channels 4.1.0 (WebSocket support)
- Daphne 4.1.2 (ASGI server)
- OpenAI API (GPT-4, GPT-4o, GPT-3.5-turbo)
- Deepgram Nova-3 API (Speech-to-Text)
- PyPDF2 (Resume parsing)

**Frontend:**
- HTML5 / CSS3
- Vanilla JavaScript
- MediaRecorder API
- WebSocket API
- Marked.js (Markdown rendering)

**Desktop:**
- Electron (Transparent overlay window)
- IPC (Inter-Process Communication)

### ğŸ“ Project Structure

```
ai-interview-copilot/
â”œâ”€â”€ copilot/                    # Main Django app
â”‚   â”œâ”€â”€ consumers.py           # WebSocket consumer
â”‚   â”œâ”€â”€ utils.py               # Helper functions (question extraction, response generation)
â”‚   â”œâ”€â”€ views.py               # HTTP views
â”‚   â””â”€â”€ urls.py                # URL routing
â”œâ”€â”€ electron/                   # Electron overlay app
â”‚   â”œâ”€â”€ main.js                # Electron main process
â”‚   â”œâ”€â”€ index.html             # Overlay UI
â”‚   â”œâ”€â”€ css/style.css          # Overlay styles
â”‚   â””â”€â”€ js/renderer.js         # Renderer process
â”œâ”€â”€ static/copilot/            # Static files
â”‚   â”œâ”€â”€ css/style.css          # Web interface styles
â”‚   â”œâ”€â”€ js/interview.js        # Web interface logic
â”‚   â””â”€â”€ images/                # Assets
â”œâ”€â”€ templates/                  # Django templates
â”‚   â””â”€â”€ index.html             # Main interview interface
â”œâ”€â”€ resume/                     # Resume PDFs (gitignored)
â”œâ”€â”€ job_description/           # Job description PDFs (gitignored)
â”œâ”€â”€ interview_copilot/         # Django project settings
â”‚   â”œâ”€â”€ settings.py            # Project configuration
â”‚   â”œâ”€â”€ asgi.py                # ASGI configuration
â”‚   â””â”€â”€ routing.py             # WebSocket routing
â”œâ”€â”€ manage.py                  # Django management script
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

### ğŸš€ Installation

#### Prerequisites

- Python 3.10+
- Node.js 16+ (for Electron)
- npm or yarn
- OpenAI API key
- Deepgram API key ($200 free credits, 750 hours of transcription)

#### Step 1: Clone the Repository

```bash
git clone https://github.com/maikonrenner/InterviewCo-pilot.git
cd InterviewCo-pilot
```

#### Step 2: Set Up Python Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install --upgrade openai
```

#### Step 3: Configure Environment Variables

Create a `.env` file in the `interview_copilot/` directory:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Deepgram Configuration
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# Django Settings
SECRET_KEY=your_django_secret_key_here
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
```

**Get API Keys:**
- OpenAI: [https://platform.openai.com/signup/](https://platform.openai.com/signup/) ([Tutorial](https://youtu.be/OB99E7Y1cMA?si=uEbJeVK5w8UYrHlw))
- Deepgram: [https://console.deepgram.com/signup](https://console.deepgram.com/signup) (Free $200 credits)

#### Step 4: Set Up Resume and Job Description

1. Create directories for your documents:
```bash
mkdir resume
mkdir job_description
```

2. Add your resume PDF to `resume/` folder
3. Add job description PDF to `job_description/` folder

#### Step 5: Run Django Server

```bash
# Apply migrations
python manage.py migrate

# Run server on port 8004
python manage.py runserver 8004
```

#### Step 6: Set Up Electron Overlay (Optional)

```bash
cd electron
npm install
npm start
```

### ğŸ’» Usage

#### Web Interface

1. Open browser: `http://localhost:8004`
2. Click **"Start Interview"** to begin audio capture
3. Select audio input source (microphone or screen audio)
4. Allow microphone permissions
5. Speak your questions - live transcription appears in yellow box
6. Press **ENTER** or click **Send** to get AI response
7. Click **"Open Overlay"** to launch Electron window (optional)

#### Electron Overlay

1. Launch automatically from web interface OR run manually:
```bash
cd electron
npm start
```

2. Position the overlay window on your screen
3. Adjust opacity using slider (10% - 100%)
4. Live transcript mirrors from web interface
5. Press **ENTER** to send question to AI
6. View clean question + AI response in conversation area

### ğŸ”§ Configuration

#### Change AI Models

Edit `static/copilot/js/interview.js`:

```javascript
// Line 103: Default model for responses
model: 'gpt-4o' // Options: 'gpt-4', 'gpt-4o'
```

#### Adjust Response Length

Edit `copilot/utils.py`:

```python
# Line 70: Resume summary tokens
max_tokens=2000

# Line 122: Question extraction tokens
max_tokens=300
```

#### Customize System Prompt

Edit `copilot/utils.py` starting at line 132 to modify the AI persona and response format.

### ğŸ§ª Key Features Explained

#### 1. Smart Question Extraction

The system uses GPT-3.5-turbo to extract clean questions from potentially long, cluttered transcripts:

**Input (Transcript):**
```
"Insert some duplicate records. Okay, as of now. Insert into EMPL one.
So I'll take a EMPL one, and I will try to insert some duplicate records.
So I will insert the duplicate records. Okay? And let us try to see,
how actually we can solve the next question..."
```

**Output (Extracted):**
```
"How do you find duplicate records in a table?"
```

#### 2. Context-Aware Responses

The AI maintains full conversation history and personalizes responses based on:
- Complete resume summary (2000 tokens)
- Job description context
- Previous conversation turns
- User's technical background

#### 3. Multi-Question Handling

When multiple questions are asked in one transcript, the system:
- Extracts ALL questions while preserving context
- Sends full transcript to LLM for comprehensive understanding
- Displays clean, formatted questions in UI

#### 4. Real-Time Broadcast

Uses Django Channels group messaging to broadcast live transcripts to:
- All connected web clients
- Electron overlay instances
- Maintains synchronization across all interfaces

### ğŸ” Security Notes

- **Never commit** `.env` files with API keys
- **Never commit** resume/job description PDFs (contains personal data)
- Use environment variables for all sensitive configuration
- `.gitignore` is configured to exclude sensitive files

### ğŸ› Troubleshooting

#### WebSocket Connection Issues

```python
# Check if channel layer is configured in settings.py
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels.layers.InMemoryChannelLayer'
    }
}
```

#### Electron Won't Launch

```bash
# Reinstall Electron dependencies
cd electron
rm -rf node_modules
npm install
npm start
```

#### Audio Capture Not Working

- Ensure browser permissions are granted
- Use HTTPS or localhost (required for MediaRecorder API)
- Check browser console for errors

### ğŸ“ License

MIT License - feel free to use this project for personal or commercial purposes.

### ğŸ‘¨â€ğŸ’» Author

**Maikon Renner**
- GitHub: [@maikonrenner](https://github.com/maikonrenner)
- Project: [InterviewCo-pilot](https://github.com/maikonrenner/InterviewCo-pilot)

### â­ Support

If you find this project helpful, please consider giving it a star on GitHub!

---

## PortuguÃªs

### ğŸŒŸ VisÃ£o Geral

AI Interview Co-pilot Ã© um assistente inteligente em tempo real projetado para ajudÃ¡-lo a ter sucesso em entrevistas tÃ©cnicas. Ele combina transcriÃ§Ã£o de fala para texto ao vivo, extraÃ§Ã£o de perguntas com IA e geraÃ§Ã£o de respostas conscientes do contexto para fornecer sugestÃµes instantÃ¢neas e personalizadas.

### âœ¨ Recursos Principais

- **ğŸ¤ TranscriÃ§Ã£o ao Vivo**: ConversÃ£o de fala em texto em tempo real usando Deepgram Nova-3 API
- **ğŸ–¥ï¸ Overlay Electron**: Janela transparente sempre visÃ­vel para experiÃªncia de entrevista perfeita
- **ğŸ¤– Respostas com IA**: Respostas conscientes do contexto usando modelos GPT-4/GPT-4o
- **ğŸ§  ExtraÃ§Ã£o Inteligente de Perguntas**: Extrai automaticamente perguntas limpas de transcriÃ§Ãµes longas e poluÃ­das
- **ğŸ“„ AnÃ¡lise de CurrÃ­culo**: AnÃ¡lise detalhada e resumo do CV para respostas personalizadas
- **ğŸŒ Suporte Multi-idioma**: Suporta inglÃªs, portuguÃªs, francÃªs, espanhol e alemÃ£o
- **ğŸ”„ Streaming em Tempo Real**: Entrega instantÃ¢nea de respostas via WebSocket
- **ğŸ¨ Interface Moderna**: Interface limpa e responsiva com espelhamento de transcriÃ§Ã£o ao vivo

### ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI Interview Co-pilot                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Interface Web   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Overlay Electronâ”‚
â”‚   (Porta 8004)   â”‚          â”‚  (Transparente)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚     WebSocket (Broadcast)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Django Channels          â”‚
         â”‚    (WebSocket Consumer)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ExtraÃ§Ã£o de Perguntas      â”‚
         â”‚  (GPT-3.5-turbo)           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  GeraÃ§Ã£o de Respostas       â”‚
         â”‚  (GPT-4/GPT-4o)            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Fluxo de Dados

```
1. ğŸ¤ UsuÃ¡rio fala durante a entrevista
   â†“
2. ğŸ”Š Navegador captura Ã¡udio (MediaRecorder API)
   â†“
3. ğŸ“¡ Ãudio enviado para Deepgram Nova-3 API
   â†“
4. ğŸ“ TranscriÃ§Ã£o ao vivo gerada (interim + final)
   â†“
5. ğŸ”„ TranscriÃ§Ã£o transmitida via WebSocket para:
   - Interface web (exibiÃ§Ã£o)
   - Overlay Electron (exibiÃ§Ã£o espelhada)
   â†“
6. âœ… UsuÃ¡rio pressiona ENTER para enviar pergunta
   â†“
7. ğŸ§¹ GPT-3.5-turbo extrai pergunta(s) limpa(s)
   â†“
8. ğŸ“„ TranscriÃ§Ã£o completa enviada ao histÃ³rico de conversa
   â†“
9. ğŸ¤– GPT-4/GPT-4o gera resposta consciente do contexto
   â†“
10. ğŸ’¬ Resposta transmitida de volta em tempo real
```

### ğŸ“¦ Stack TecnolÃ³gico

**Backend:**
- Django 5.1.2
- Django Channels 4.1.0 (suporte WebSocket)
- Daphne 4.1.2 (servidor ASGI)
- OpenAI API (GPT-4, GPT-4o, GPT-3.5-turbo)
- Deepgram Nova-3 API (Speech-to-Text)
- PyPDF2 (anÃ¡lise de currÃ­culo)

**Frontend:**
- HTML5 / CSS3
- JavaScript Vanilla
- MediaRecorder API
- WebSocket API
- Marked.js (renderizaÃ§Ã£o Markdown)

**Desktop:**
- Electron (janela overlay transparente)
- IPC (comunicaÃ§Ã£o entre processos)

### ğŸš€ InstalaÃ§Ã£o

#### PrÃ©-requisitos

- Python 3.10+
- Node.js 16+ (para Electron)
- npm ou yarn
- Chave API OpenAI
- Chave API Deepgram (crÃ©ditos grÃ¡tis de $200, 750 horas de transcriÃ§Ã£o)

#### Passo 1: Clonar o RepositÃ³rio

```bash
git clone https://github.com/maikonrenner/InterviewCo-pilot.git
cd InterviewCo-pilot
```

#### Passo 2: Configurar Ambiente Python

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
pip install --upgrade openai
```

#### Passo 3: Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` no diretÃ³rio `interview_copilot/`:

```env
# ConfiguraÃ§Ã£o OpenAI
OPENAI_API_KEY=sua_chave_api_openai_aqui

# ConfiguraÃ§Ã£o Deepgram
DEEPGRAM_API_KEY=sua_chave_api_deepgram_aqui

# ConfiguraÃ§Ãµes Django
SECRET_KEY=sua_chave_secreta_django_aqui
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
```

**Obter Chaves de API:**
- OpenAI: [https://platform.openai.com/signup/](https://platform.openai.com/signup/) ([Tutorial](https://youtu.be/OB99E7Y1cMA?si=uEbJeVK5w8UYrHlw))
- Deepgram: [https://console.deepgram.com/signup](https://console.deepgram.com/signup) (CrÃ©ditos grÃ¡tis de $200)

#### Passo 4: Configurar CurrÃ­culo e DescriÃ§Ã£o da Vaga

1. Criar diretÃ³rios para seus documentos:
```bash
mkdir resume
mkdir job_description
```

2. Adicionar seu currÃ­culo em PDF na pasta `resume/`
3. Adicionar descriÃ§Ã£o da vaga em PDF na pasta `job_description/`

#### Passo 5: Executar Servidor Django

```bash
# Aplicar migraÃ§Ãµes
python manage.py migrate

# Executar servidor na porta 8004
python manage.py runserver 8004
```

#### Passo 6: Configurar Overlay Electron (Opcional)

```bash
cd electron
npm install
npm start
```

### ğŸ’» Uso

#### Interface Web

1. Abrir navegador: `http://localhost:8004`
2. Clicar em **"Start Interview"** para iniciar captura de Ã¡udio
3. Selecionar fonte de entrada de Ã¡udio (microfone ou Ã¡udio da tela)
4. Permitir permissÃµes de microfone
5. Falar suas perguntas - transcriÃ§Ã£o ao vivo aparece na caixa amarela
6. Pressionar **ENTER** ou clicar em **Send** para obter resposta da IA
7. Clicar em **"Open Overlay"** para abrir janela Electron (opcional)

#### Overlay Electron

1. Iniciar automaticamente da interface web OU executar manualmente:
```bash
cd electron
npm start
```

2. Posicionar a janela overlay na tela
3. Ajustar opacidade usando o controle deslizante (10% - 100%)
4. TranscriÃ§Ã£o ao vivo espelhada da interface web
5. Pressionar **ENTER** para enviar pergunta Ã  IA
6. Ver pergunta limpa + resposta da IA na Ã¡rea de conversa

### ğŸ§ª Recursos Principais Explicados

#### 1. ExtraÃ§Ã£o Inteligente de Perguntas

O sistema usa GPT-3.5-turbo para extrair perguntas limpas de transcriÃ§Ãµes potencialmente longas e confusas:

**Entrada (TranscriÃ§Ã£o):**
```
"Insert some duplicate records. Okay, as of now. Insert into EMPL one.
So I'll take a EMPL one, and I will try to insert some duplicate records.
So I will insert the duplicate records. Okay? And let us try to see,
how actually we can solve the next question..."
```

**SaÃ­da (ExtraÃ­da):**
```
"Como encontrar registros duplicados em uma tabela?"
```

#### 2. Respostas Conscientes do Contexto

A IA mantÃ©m histÃ³rico completo da conversa e personaliza respostas baseadas em:
- Resumo completo do currÃ­culo (2000 tokens)
- Contexto da descriÃ§Ã£o da vaga
- Turnos anteriores da conversa
- Background tÃ©cnico do usuÃ¡rio

#### 3. Tratamento de MÃºltiplas Perguntas

Quando mÃºltiplas perguntas sÃ£o feitas em uma transcriÃ§Ã£o, o sistema:
- Extrai TODAS as perguntas preservando o contexto
- Envia transcriÃ§Ã£o completa ao LLM para compreensÃ£o abrangente
- Exibe perguntas limpas e formatadas na UI

#### 4. Broadcast em Tempo Real

Usa mensagens de grupo do Django Channels para transmitir transcriÃ§Ãµes ao vivo para:
- Todos os clientes web conectados
- InstÃ¢ncias do overlay Electron
- MantÃ©m sincronizaÃ§Ã£o entre todas as interfaces

### ğŸ” Notas de SeguranÃ§a

- **Nunca faÃ§a commit** de arquivos `.env` com chaves de API
- **Nunca faÃ§a commit** de PDFs de currÃ­culo/descriÃ§Ã£o de vaga (contÃ©m dados pessoais)
- Use variÃ¡veis de ambiente para todas as configuraÃ§Ãµes sensÃ­veis
- `.gitignore` estÃ¡ configurado para excluir arquivos sensÃ­veis

### ğŸ› SoluÃ§Ã£o de Problemas

#### Problemas de ConexÃ£o WebSocket

```python
# Verifique se a camada de canais estÃ¡ configurada em settings.py
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels.layers.InMemoryChannelLayer'
    }
}
```

#### Electron NÃ£o Inicia

```bash
# Reinstalar dependÃªncias do Electron
cd electron
rm -rf node_modules
npm install
npm start
```

#### Captura de Ãudio NÃ£o Funciona

- Certifique-se de que as permissÃµes do navegador foram concedidas
- Use HTTPS ou localhost (necessÃ¡rio para MediaRecorder API)
- Verifique o console do navegador para erros

### ğŸ“ LicenÃ§a

LicenÃ§a MIT - sinta-se livre para usar este projeto para fins pessoais ou comerciais.

### ğŸ‘¨â€ğŸ’» Autor

**Maikon Renner**
- GitHub: [@maikonrenner](https://github.com/maikonrenner)
- Projeto: [InterviewCo-pilot](https://github.com/maikonrenner/InterviewCo-pilot)

### â­ Apoie

Se vocÃª achar este projeto Ãºtil, considere dar uma estrela no GitHub!

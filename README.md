# ğŸ¯ AI Interview Co-pilot

> Real-time AI-powered interview assistant with live transcription, intelligent question extraction, and context-aware responses.

[English](#english) | [PortuguÃªs](#portuguÃªs)

---

## English

### ğŸŒŸ Overview

AI Interview Co-pilot is an intelligent real-time assistant designed to help you ace technical interviews. It combines live speech-to-text transcription, AI-powered question extraction, and context-aware response generation to provide instant, personalized interview suggestions.

### âœ¨ Key Features

- **ğŸ¤ Live Transcription**: Real-time speech-to-text using Deepgram Nova-3 API
- **ğŸ™ï¸ Dual Audio Capture**: Simultaneously captures system audio (screen sharing) and microphone with automatic speaker identification
- **ğŸ‘¥ Speaker Diarization**: Automatically distinguishes between Interviewer and Candidate voices with color-coded labels
- **ğŸ–¥ï¸ Electron Overlay**: Transparent, always-on-top overlay window for seamless interview experience
- **ğŸ¤– AI-Powered Responses**: Context-aware answers using GPT-4/GPT-4o-mini or local Ollama models
- **ğŸ  Local LLM Support**: Run completely offline with Ollama (llama3.2, qwen2.5, deepseek-r1, etc.)
- **âš¡ FAQ Cache System**: Instant responses for frequently asked questions with hit tracking
- **ğŸ§  Smart Question Extraction**: Automatically extracts clean questions from long, cluttered transcripts
- **ğŸ“„ Resume Analysis**: Detailed CV parsing and summarization for personalized responses
- **ğŸŒ Multi-language Support**: Automatic multi-language detection (English, Portuguese, French, Spanish, German, etc.)
- **ğŸ”„ Real-time Streaming**: WebSocket-based streaming for instant response delivery
- **ğŸ¨ Modern UI**: Clean, responsive interface with live transcript mirroring
- **ğŸ“Š Dashboard Analytics**: Interactive charts and metrics to track interview performance
- **ğŸ“… Google Calendar Integration**: Sync and view upcoming/past interviews from Google Calendar
- **âš™ï¸ Settings Management**: Browser-based configuration for API keys (OpenAI and Deepgram)
- **ğŸ“ AI Resume Builder**: Upload and analyze resumes/job descriptions with AI-powered summaries

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI Interview Co-pilot                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Electron Overlayâ”‚
â”‚   (Port 8004)    â”‚          â”‚  (Transparent)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚     WebSocket (Broadcast)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Django Channels          â”‚
         â”‚    (WebSocket Consumer)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Question Extraction        â”‚
         â”‚  (GPT-3.5-turbo)           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Response Generation        â”‚
         â”‚  (GPT-4/GPT-4o)            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Data Flow

```
1. ğŸ¤ User speaks during interview
   â†“
2. ğŸ”Š Browser captures audio (MediaRecorder API)
   â†“
3. ğŸ“¡ Audio sent to Deepgram Nova-3 API
   â†“
4. ğŸ“ Live transcript generated (interim + final)
   â†“
5. ğŸ”„ Transcript broadcast via WebSocket to:
   - Web interface (display)
   - Electron overlay (mirror display)
   â†“
6. âœ… User presses ENTER to submit question
   â†“
7. ğŸ§¹ GPT-3.5-turbo extracts clean question(s)
   â†“
8. ğŸ“„ Full transcript sent to conversation history
   â†“
9. ğŸ¤– GPT-4/GPT-4o generates context-aware response
   â†“
10. ğŸ’¬ Response streamed back in real-time
```

### ğŸ“¦ Technology Stack

**Backend:**
- Django 5.1.2
- Django Channels 4.1.0 (WebSocket support)
- Daphne 4.1.2 (ASGI server)
- OpenAI API (GPT-4, GPT-4o, GPT-4o-mini, GPT-3.5-turbo)
- Ollama (Local LLM support - llama3.2, qwen2.5, deepseek-r1, etc.)
- Deepgram Nova-3 API (Speech-to-Text)
- PyPDF2 (Resume parsing)

**Frontend:**
- HTML5 / CSS3
- Vanilla JavaScript
- MediaRecorder API
- WebSocket API
- Marked.js (Markdown rendering)

**Desktop:**
- Electron (Transparent overlay window)
- IPC (Inter-Process Communication)

### ğŸ“ Project Structure

```
ai-interview-copilot/
â”œâ”€â”€ copilot/                    # Main Django app
â”‚   â”œâ”€â”€ consumers.py           # WebSocket consumer
â”‚   â”œâ”€â”€ utils.py               # Helper functions (question extraction, response generation)
â”‚   â”œâ”€â”€ views.py               # HTTP views
â”‚   â””â”€â”€ urls.py                # URL routing
â”œâ”€â”€ electron/                   # Electron overlay app
â”‚   â”œâ”€â”€ main.js                # Electron main process
â”‚   â”œâ”€â”€ index.html             # Overlay UI
â”‚   â”œâ”€â”€ css/style.css          # Overlay styles
â”‚   â””â”€â”€ js/renderer.js         # Renderer process
â”œâ”€â”€ static/copilot/            # Static files
â”‚   â”œâ”€â”€ css/style.css          # Web interface styles
â”‚   â”œâ”€â”€ js/interview.js        # Web interface logic
â”‚   â””â”€â”€ images/                # Assets
â”œâ”€â”€ templates/                  # Django templates
â”‚   â””â”€â”€ index.html             # Main interview interface
â”œâ”€â”€ resume/                     # Resume PDFs (gitignored)
â”œâ”€â”€ job_description/           # Job description PDFs (gitignored)
â”œâ”€â”€ interview_copilot/         # Django project settings
â”‚   â”œâ”€â”€ settings.py            # Project configuration
â”‚   â”œâ”€â”€ asgi.py                # ASGI configuration
â”‚   â””â”€â”€ routing.py             # WebSocket routing
â”œâ”€â”€ manage.py                  # Django management script
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # This file
```

### ğŸš€ Installation

#### Prerequisites

- Python 3.10+
- Node.js 16+ (for Electron)
- npm or yarn
- OpenAI API key
- Deepgram API key ($200 free credits, 750 hours of transcription)

#### Step 1: Clone the Repository

```bash
git clone https://github.com/maikonrenner/InterviewCo-pilot.git
cd InterviewCo-pilot
```

#### Step 2: Set Up Python Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
pip install --upgrade openai
```

#### Step 3: Configure Environment Variables

Create a `.env` file in the `interview_copilot/` directory:

```env
# LLM Provider Configuration
LLM_PROVIDER=openai  # Options: 'openai' or 'ollama'

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (if using local LLM)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2  # Options: llama3.2, qwen2.5:14b, deepseek-r1:14b, etc.

# Deepgram Configuration
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# Django Settings
SECRET_KEY=your_django_secret_key_here
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
```

**Get API Keys:**
- OpenAI: [https://platform.openai.com/signup/](https://platform.openai.com/signup/) ([Tutorial](https://youtu.be/OB99E7Y1cMA?si=uEbJeVK5w8UYrHlw))
- Deepgram: [https://console.deepgram.com/signup](https://console.deepgram.com/signup) (Free $200 credits)
- Ollama Setup: See [OLLAMA_SETUP.md](OLLAMA_SETUP.md) for complete installation guide

#### Step 4: Set Up Resume and Job Description

1. Create directories for your documents:
```bash
mkdir resume
mkdir job_description
```

2. Add your resume PDF to `resume/` folder
3. Add job description PDF to `job_description/` folder

#### Step 5: Run Django Server

```bash
# Apply migrations
python manage.py migrate

# Run server on port 8004
python manage.py runserver 8004
```

#### Step 6: Set Up Electron Overlay (Optional)

```bash
cd electron
npm install
npm start
```

### ğŸ’» Usage

#### Web Interface

1. Open browser: `http://localhost:8004`
2. Click **"ğŸ™ï¸ Iniciar Entrevista"** to begin dual audio capture
3. Allow screen sharing and microphone permissions when prompted
4. The system will capture both:
   - **System audio** (from screen sharing) â†’ Labeled as **[Interviewer]** (red)
   - **Microphone audio** â†’ Labeled as **[You]** (green)
5. Speak during the interview - live transcription with speaker labels appears
6. Press **ENTER** to send the transcript and get AI response
7. Click **"Open Overlay"** to launch Electron window (optional)
8. Click **"â¹ï¸ Parar Entrevista"** to stop the interview

#### Electron Overlay

1. Launch automatically from web interface OR run manually:
```bash
cd electron
npm start
```

2. Position the overlay window on your screen
3. Adjust opacity using slider (10% - 100%)
4. Live transcript mirrors from web interface
5. Press **ENTER** to send question to AI
6. View clean question + AI response in conversation area

### ğŸ”§ Configuration

#### Change AI Models

Edit `static/copilot/js/interview.js`:

```javascript
// Line 103: Default model for responses
model: 'gpt-4o' // Options: 'gpt-4', 'gpt-4o'
```

#### Adjust Response Length

Edit `copilot/utils.py`:

```python
# Line 290: Resume summary tokens
max_tokens=3000

# Line 567: AI response tokens (OpenAI)
max_tokens=450

# Line 626: AI response tokens (Ollama)
'num_predict': 450
```

#### Switch Between OpenAI and Ollama

Edit `interview_copilot/.env`:

```env
# Use OpenAI (cloud)
LLM_PROVIDER=openai

# OR use Ollama (local)
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.2
```

#### Customize System Prompt

Edit `copilot/utils.py` starting at line 525 to modify the AI persona and response format. The current prompt is optimized for concise, context-aware responses (2-4 sentences, 450 tokens max).

### ğŸ§ª Key Features Explained

#### 1. Dual Audio Capture with Speaker Diarization

The system simultaneously captures audio from two sources and automatically identifies speakers:

**Audio Sources:**
- **Screen Sharing Audio**: Captures the interviewer's voice from virtual meeting platforms (Zoom, Teams, Google Meet)
- **Microphone Audio**: Captures your voice (candidate) directly from your microphone

**How It Works:**
```
1. User clicks "ğŸ™ï¸ Iniciar Entrevista"
   â†“
2. Browser requests two permissions:
   - Screen sharing with audio (getDisplayMedia)
   - Microphone access (getUserMedia)
   â†“
3. Web Audio API combines both streams into one
   â†“
4. Combined audio sent to Deepgram with diarization enabled
   â†“
5. Deepgram identifies speakers (Speaker 0, Speaker 1)
   â†“
6. System maps speakers to roles:
   - First speaker (usually from screen) â†’ [Interviewer] (red label)
   - Second speaker (usually from mic) â†’ [You] (green label)
   â†“
7. Live transcript shows color-coded speaker labels
```

**Visual Indicators:**
- ğŸŸ¥ **[Interviewer]**: Red background - Questions from the interviewer
- ğŸŸ© **[You]**: Green background - Your responses

This feature is perfect for virtual interviews where you need to capture both sides of the conversation accurately.

#### 2. Smart Question Extraction

The system uses GPT-3.5-turbo to extract clean questions from potentially long, cluttered transcripts:

**Input (Transcript):**
```
"Insert some duplicate records. Okay, as of now. Insert into EMPL one.
So I'll take a EMPL one, and I will try to insert some duplicate records.
So I will insert the duplicate records. Okay? And let us try to see,
how actually we can solve the next question..."
```

**Output (Extracted):**
```
"How do you find duplicate records in a table?"
```

#### 2. Context-Aware Responses

The AI maintains full conversation history and personalizes responses based on:
- Complete resume summary (2000 tokens)
- Job description context
- Previous conversation turns
- User's technical background

#### 3. Multi-Question Handling

When multiple questions are asked in one transcript, the system:
- Extracts ALL questions while preserving context
- Sends full transcript to LLM for comprehensive understanding
- Displays clean, formatted questions in UI

#### 4. Real-Time Broadcast

Uses Django Channels group messaging to broadcast live transcripts to:
- All connected web clients
- Electron overlay instances
- Maintains synchronization across all interfaces

#### 5. Dashboard Analytics

Track your interview performance with interactive visualizations:
- **Interview Activity Chart**: 7-day history of interview sessions
- **Language Distribution**: Pie chart of languages used in interviews
- **Questions Answered**: Bar chart tracking question count over time
- **AI Model Performance**: Compare response times across different models
- **Session Metrics**: Total interviews, average duration, questions answered, AI response time

All data is stored locally in the browser's localStorage.

#### 6. Google Calendar Integration

Automatically sync interview schedules from Google Calendar:
- **Visual Calendar**: Color-coded day blocks (ğŸŸ© green for upcoming, â¬œ gray for past interviews)
- **Smart Filtering**: Automatically detects interview-related events using multilingual keywords
- **Event Details**: Click on any day to view interview details (time, description, location)
- **60-Day Range**: Shows interviews from 60 days back to 60 days ahead

**Supported Keywords**: interview, entrevista, entretien, meeting, rencontre, discussion, Ã©change, call, appel

#### 7. Settings Management

Configure API keys directly in the browser (no backend required):
- **OpenAI API Key**: Configure your OpenAI key for GPT models
- **Deepgram API Key**: Configure your Deepgram key for speech-to-text
- **Default AI Model**: Select preferred GPT model (GPT-4o, GPT-4o Mini, GPT-4 Turbo, etc.)
- **Auto-Language Detection**: System automatically detects and transcribes multiple languages
- **Local Storage**: All settings stored securely in browser's localStorage

**Visual Feedback**:
- Button changes to "â³ Saving..." â†’ "âœ… Saved!"
- Fields turn green when successfully saved
- Success/error messages with animations

#### 8. AI Resume Builder

Upload and analyze documents with AI-powered summaries:
- **Resume Upload**: Drag & drop or browse for resume files (PDF, DOCX, TXT)
- **Job Description Input**: Paste text or upload file for job descriptions
- **AI Summaries**: GPT-4 generates concise summaries of both documents
- **Interview Details**: Add company name and job title for context
- **Version History**: Track multiple document versions
- **Document Management**: View, delete, and manage uploaded documents

#### 9. FAQ Cache System

Pre-load frequently asked questions for instant responses:
- **Auto-Load**: Automatically loads FAQ from `faq_data_eng.json` on startup
- **Instant Responses**: Cached answers returned in <50ms (no LLM call)
- **Hit Tracking**: Monitors which questions are most frequently asked
- **Cache Management**: Upload new FAQ files via Settings page
- **Stats Dashboard**: View cache hit rate and most popular questions
- **Smart Matching**: Normalizes questions for fuzzy matching (case-insensitive, punctuation-agnostic)

#### 10. Local LLM with Ollama

Run the entire system offline with local models:
- **Privacy-First**: All data stays on your machine
- **Cost-Free**: No API costs after initial setup
- **Fast Inference**: Optimized for M-series Macs and NVIDIA GPUs
- **Model Options**: llama3.2 (fast), qwen2.5:14b (balanced), deepseek-r1:14b (quality)
- **Easy Switch**: Toggle between OpenAI and Ollama in settings
- **Complete Guide**: See [OLLAMA_SETUP.md](OLLAMA_SETUP.md) for installation

### ğŸ” Security Notes

- **Never commit** `.env` files with API keys
- **Never commit** resume/job description PDFs (contains personal data)
- Use environment variables for all sensitive configuration
- `.gitignore` is configured to exclude sensitive files

### ğŸ› Troubleshooting

#### WebSocket Connection Issues

```python
# Check if channel layer is configured in settings.py
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels.layers.InMemoryChannelLayer'
    }
}
```

#### Electron Won't Launch

```bash
# Reinstall Electron dependencies
cd electron
rm -rf node_modules
npm install
npm start
```

#### Audio Capture Not Working

- Ensure browser permissions are granted
- Use HTTPS or localhost (required for MediaRecorder API)
- Check browser console for errors

### ğŸ“ License

MIT License - feel free to use this project for personal or commercial purposes.

### ğŸ‘¨â€ğŸ’» Author

**Maikon Renner**
- GitHub: [@maikonrenner](https://github.com/maikonrenner)
- Project: [InterviewCo-pilot](https://github.com/maikonrenner/InterviewCo-pilot)

### â­ Support

If you find this project helpful, please consider giving it a star on GitHub!

---

## PortuguÃªs

### ğŸŒŸ VisÃ£o Geral

AI Interview Co-pilot Ã© um assistente inteligente em tempo real projetado para ajudÃ¡-lo a ter sucesso em entrevistas tÃ©cnicas. Ele combina transcriÃ§Ã£o de fala para texto ao vivo, extraÃ§Ã£o de perguntas com IA e geraÃ§Ã£o de respostas conscientes do contexto para fornecer sugestÃµes instantÃ¢neas e personalizadas.

### âœ¨ Recursos Principais

- **ğŸ¤ TranscriÃ§Ã£o ao Vivo**: ConversÃ£o de fala em texto em tempo real usando Deepgram Nova-3 API
- **ğŸ™ï¸ Captura Dupla de Ãudio**: Captura simultaneamente Ã¡udio do sistema (compartilhamento de tela) e microfone com identificaÃ§Ã£o automÃ¡tica de locutores
- **ğŸ‘¥ DiarizaÃ§Ã£o de Locutores**: Distingue automaticamente entre Entrevistador e Candidato com etiquetas coloridas
- **ğŸ–¥ï¸ Overlay Electron**: Janela transparente sempre visÃ­vel para experiÃªncia de entrevista perfeita
- **ğŸ¤– Respostas com IA**: Respostas conscientes do contexto usando modelos GPT-4/GPT-4o
- **ğŸ§  ExtraÃ§Ã£o Inteligente de Perguntas**: Extrai automaticamente perguntas limpas de transcriÃ§Ãµes longas e poluÃ­das
- **ğŸ“„ AnÃ¡lise de CurrÃ­culo**: AnÃ¡lise detalhada e resumo do CV para respostas personalizadas
- **ğŸŒ Suporte Multi-idioma**: DetecÃ§Ã£o automÃ¡tica de mÃºltiplos idiomas (inglÃªs, portuguÃªs, francÃªs, espanhol, alemÃ£o, etc.)
- **ğŸ”„ Streaming em Tempo Real**: Entrega instantÃ¢nea de respostas via WebSocket
- **ğŸ¨ Interface Moderna**: Interface limpa e responsiva com espelhamento de transcriÃ§Ã£o ao vivo
- **ğŸ“Š Dashboard Analytics**: GrÃ¡ficos interativos e mÃ©tricas para acompanhar desempenho em entrevistas
- **ğŸ“… IntegraÃ§Ã£o com Google Calendar**: Sincronize e visualize entrevistas futuras/passadas do Google Calendar
- **âš™ï¸ Gerenciamento de ConfiguraÃ§Ãµes**: ConfiguraÃ§Ã£o de chaves de API (OpenAI e Deepgram) no navegador
- **ğŸ“ AI Resume Builder**: Upload e anÃ¡lise de currÃ­culos/descriÃ§Ãµes de vaga com resumos gerados por IA

### ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI Interview Co-pilot                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Interface Web   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Overlay Electronâ”‚
â”‚   (Porta 8004)   â”‚          â”‚  (Transparente)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚     WebSocket (Broadcast)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Django Channels          â”‚
         â”‚    (WebSocket Consumer)     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ExtraÃ§Ã£o de Perguntas      â”‚
         â”‚  (GPT-3.5-turbo)           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  GeraÃ§Ã£o de Respostas       â”‚
         â”‚  (GPT-4/GPT-4o)            â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Fluxo de Dados

```
1. ğŸ¤ UsuÃ¡rio fala durante a entrevista
   â†“
2. ğŸ”Š Navegador captura Ã¡udio (MediaRecorder API)
   â†“
3. ğŸ“¡ Ãudio enviado para Deepgram Nova-3 API
   â†“
4. ğŸ“ TranscriÃ§Ã£o ao vivo gerada (interim + final)
   â†“
5. ğŸ”„ TranscriÃ§Ã£o transmitida via WebSocket para:
   - Interface web (exibiÃ§Ã£o)
   - Overlay Electron (exibiÃ§Ã£o espelhada)
   â†“
6. âœ… UsuÃ¡rio pressiona ENTER para enviar pergunta
   â†“
7. ğŸ§¹ GPT-3.5-turbo extrai pergunta(s) limpa(s)
   â†“
8. ğŸ“„ TranscriÃ§Ã£o completa enviada ao histÃ³rico de conversa
   â†“
9. ğŸ¤– GPT-4/GPT-4o gera resposta consciente do contexto
   â†“
10. ğŸ’¬ Resposta transmitida de volta em tempo real
```

### ğŸ“¦ Stack TecnolÃ³gico

**Backend:**
- Django 5.1.2
- Django Channels 4.1.0 (suporte WebSocket)
- Daphne 4.1.2 (servidor ASGI)
- OpenAI API (GPT-4, GPT-4o, GPT-3.5-turbo)
- Deepgram Nova-3 API (Speech-to-Text)
- PyPDF2 (anÃ¡lise de currÃ­culo)

**Frontend:**
- HTML5 / CSS3
- JavaScript Vanilla
- MediaRecorder API
- WebSocket API
- Marked.js (renderizaÃ§Ã£o Markdown)

**Desktop:**
- Electron (janela overlay transparente)
- IPC (comunicaÃ§Ã£o entre processos)

### ğŸš€ InstalaÃ§Ã£o

#### PrÃ©-requisitos

- Python 3.10+
- Node.js 16+ (para Electron)
- npm ou yarn
- Chave API OpenAI
- Chave API Deepgram (crÃ©ditos grÃ¡tis de $200, 750 horas de transcriÃ§Ã£o)

#### Passo 1: Clonar o RepositÃ³rio

```bash
git clone https://github.com/maikonrenner/InterviewCo-pilot.git
cd InterviewCo-pilot
```

#### Passo 2: Configurar Ambiente Python

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
pip install --upgrade openai
```

#### Passo 3: Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` no diretÃ³rio `interview_copilot/`:

```env
# ConfiguraÃ§Ã£o OpenAI
OPENAI_API_KEY=sua_chave_api_openai_aqui

# ConfiguraÃ§Ã£o Deepgram
DEEPGRAM_API_KEY=sua_chave_api_deepgram_aqui

# ConfiguraÃ§Ãµes Django
SECRET_KEY=sua_chave_secreta_django_aqui
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1
```

**Obter Chaves de API:**
- OpenAI: [https://platform.openai.com/signup/](https://platform.openai.com/signup/) ([Tutorial](https://youtu.be/OB99E7Y1cMA?si=uEbJeVK5w8UYrHlw))
- Deepgram: [https://console.deepgram.com/signup](https://console.deepgram.com/signup) (CrÃ©ditos grÃ¡tis de $200)

#### Passo 4: Configurar CurrÃ­culo e DescriÃ§Ã£o da Vaga

1. Criar diretÃ³rios para seus documentos:
```bash
mkdir resume
mkdir job_description
```

2. Adicionar seu currÃ­culo em PDF na pasta `resume/`
3. Adicionar descriÃ§Ã£o da vaga em PDF na pasta `job_description/`

#### Passo 5: Executar Servidor Django

```bash
# Aplicar migraÃ§Ãµes
python manage.py migrate

# Executar servidor na porta 8004
python manage.py runserver 8004
```

#### Passo 6: Configurar Overlay Electron (Opcional)

```bash
cd electron
npm install
npm start
```

### ğŸ’» Uso

#### Interface Web

1. Abrir navegador: `http://localhost:8004`
2. Clicar em **"ğŸ™ï¸ Iniciar Entrevista"** para iniciar captura dupla de Ã¡udio
3. Permitir permissÃµes de compartilhamento de tela e microfone quando solicitado
4. O sistema irÃ¡ capturar ambos:
   - **Ãudio do sistema** (do compartilhamento de tela) â†’ Rotulado como **[Interviewer]** (vermelho)
   - **Ãudio do microfone** â†’ Rotulado como **[You]** (verde)
5. Fale durante a entrevista - transcriÃ§Ã£o ao vivo com etiquetas de locutor aparece
6. Pressionar **ENTER** para enviar a transcriÃ§Ã£o e obter resposta da IA
7. Clicar em **"Open Overlay"** para abrir janela Electron (opcional)
8. Clicar em **"â¹ï¸ Parar Entrevista"** para parar a entrevista

#### Overlay Electron

1. Iniciar automaticamente da interface web OU executar manualmente:
```bash
cd electron
npm start
```

2. Posicionar a janela overlay na tela
3. Ajustar opacidade usando o controle deslizante (10% - 100%)
4. TranscriÃ§Ã£o ao vivo espelhada da interface web
5. Pressionar **ENTER** para enviar pergunta Ã  IA
6. Ver pergunta limpa + resposta da IA na Ã¡rea de conversa

### ğŸ§ª Recursos Principais Explicados

#### 1. Captura Dupla de Ãudio com DiarizaÃ§Ã£o de Locutores

O sistema captura simultaneamente Ã¡udio de duas fontes e identifica automaticamente os locutores:

**Fontes de Ãudio:**
- **Ãudio do Compartilhamento de Tela**: Captura a voz do entrevistador de plataformas de reuniÃ£o virtual (Zoom, Teams, Google Meet)
- **Ãudio do Microfone**: Captura sua voz (candidato) diretamente do seu microfone

**Como Funciona:**
```
1. UsuÃ¡rio clica em "ğŸ™ï¸ Iniciar Entrevista"
   â†“
2. Navegador solicita duas permissÃµes:
   - Compartilhamento de tela com Ã¡udio (getDisplayMedia)
   - Acesso ao microfone (getUserMedia)
   â†“
3. Web Audio API combina ambos os streams em um
   â†“
4. Ãudio combinado enviado ao Deepgram com diarizaÃ§Ã£o habilitada
   â†“
5. Deepgram identifica locutores (Speaker 0, Speaker 1)
   â†“
6. Sistema mapeia locutores para funÃ§Ãµes:
   - Primeiro locutor (geralmente da tela) â†’ [Interviewer] (etiqueta vermelha)
   - Segundo locutor (geralmente do mic) â†’ [You] (etiqueta verde)
   â†“
7. TranscriÃ§Ã£o ao vivo mostra etiquetas coloridas de locutores
```

**Indicadores Visuais:**
- ğŸŸ¥ **[Interviewer]**: Fundo vermelho - Perguntas do entrevistador
- ğŸŸ© **[You]**: Fundo verde - Suas respostas

Este recurso Ã© perfeito para entrevistas virtuais onde vocÃª precisa capturar ambos os lados da conversa com precisÃ£o.

#### 2. ExtraÃ§Ã£o Inteligente de Perguntas

O sistema usa GPT-3.5-turbo para extrair perguntas limpas de transcriÃ§Ãµes potencialmente longas e confusas:

**Entrada (TranscriÃ§Ã£o):**
```
"Insert some duplicate records. Okay, as of now. Insert into EMPL one.
So I'll take a EMPL one, and I will try to insert some duplicate records.
So I will insert the duplicate records. Okay? And let us try to see,
how actually we can solve the next question..."
```

**SaÃ­da (ExtraÃ­da):**
```
"Como encontrar registros duplicados em uma tabela?"
```

#### 2. Respostas Conscientes do Contexto

A IA mantÃ©m histÃ³rico completo da conversa e personaliza respostas baseadas em:
- Resumo completo do currÃ­culo (2000 tokens)
- Contexto da descriÃ§Ã£o da vaga
- Turnos anteriores da conversa
- Background tÃ©cnico do usuÃ¡rio

#### 3. Tratamento de MÃºltiplas Perguntas

Quando mÃºltiplas perguntas sÃ£o feitas em uma transcriÃ§Ã£o, o sistema:
- Extrai TODAS as perguntas preservando o contexto
- Envia transcriÃ§Ã£o completa ao LLM para compreensÃ£o abrangente
- Exibe perguntas limpas e formatadas na UI

#### 4. Broadcast em Tempo Real

Usa mensagens de grupo do Django Channels para transmitir transcriÃ§Ãµes ao vivo para:
- Todos os clientes web conectados
- InstÃ¢ncias do overlay Electron
- MantÃ©m sincronizaÃ§Ã£o entre todas as interfaces

#### 5. Dashboard Analytics

Acompanhe seu desempenho em entrevistas com visualizaÃ§Ãµes interativas:
- **GrÃ¡fico de Atividade**: HistÃ³rico de 7 dias de sessÃµes de entrevista
- **DistribuiÃ§Ã£o de Idiomas**: GrÃ¡fico de pizza dos idiomas usados
- **Perguntas Respondidas**: GrÃ¡fico de barras rastreando quantidade de perguntas ao longo do tempo
- **Desempenho dos Modelos AI**: Compare tempos de resposta entre diferentes modelos
- **MÃ©tricas de SessÃ£o**: Total de entrevistas, duraÃ§Ã£o mÃ©dia, perguntas respondidas, tempo de resposta da IA

Todos os dados sÃ£o armazenados localmente no localStorage do navegador.

#### 6. IntegraÃ§Ã£o com Google Calendar

Sincronize automaticamente agendamentos de entrevistas do Google Calendar:
- **CalendÃ¡rio Visual**: Blocos de dias com cÃ³digo de cores (ğŸŸ© verde para futuras, â¬œ cinza para passadas)
- **Filtragem Inteligente**: Detecta automaticamente eventos relacionados a entrevistas usando palavras-chave multilÃ­ngues
- **Detalhes do Evento**: Clique em qualquer dia para ver detalhes da entrevista (hora, descriÃ§Ã£o, local)
- **Alcance de 60 Dias**: Mostra entrevistas de 60 dias atrÃ¡s atÃ© 60 dias Ã  frente

**Palavras-chave Suportadas**: interview, entrevista, entretien, meeting, rencontre, discussion, Ã©change, call, appel

#### 7. Gerenciamento de ConfiguraÃ§Ãµes

Configure chaves de API diretamente no navegador (sem necessidade de backend):
- **Chave API OpenAI**: Configure sua chave OpenAI para modelos GPT
- **Chave API Deepgram**: Configure sua chave Deepgram para conversÃ£o de fala em texto
- **Modelo AI PadrÃ£o**: Selecione o modelo GPT preferido (GPT-4o, GPT-4o Mini, GPT-4 Turbo, etc.)
- **DetecÃ§Ã£o AutomÃ¡tica de Idioma**: Sistema detecta e transcreve automaticamente mÃºltiplos idiomas
- **Armazenamento Local**: Todas as configuraÃ§Ãµes armazenadas com seguranÃ§a no localStorage do navegador

**Feedback Visual**:
- BotÃ£o muda para "â³ Saving..." â†’ "âœ… Saved!"
- Campos ficam verdes quando salvos com sucesso
- Mensagens de sucesso/erro com animaÃ§Ãµes

#### 8. AI Resume Builder

Upload e anÃ¡lise de documentos com resumos gerados por IA:
- **Upload de CurrÃ­culo**: Arraste e solte ou navegue por arquivos de currÃ­culo (PDF, DOCX, TXT)
- **Entrada de DescriÃ§Ã£o da Vaga**: Cole texto ou faÃ§a upload de arquivo para descriÃ§Ãµes de vaga
- **Resumos AI**: GPT-4 gera resumos concisos de ambos os documentos
- **Detalhes da Entrevista**: Adicione nome da empresa e tÃ­tulo da vaga para contexto
- **HistÃ³rico de VersÃµes**: Rastreie mÃºltiplas versÃµes de documentos
- **Gerenciamento de Documentos**: Visualize, exclua e gerencie documentos enviados

### ğŸ” Notas de SeguranÃ§a

- **Nunca faÃ§a commit** de arquivos `.env` com chaves de API
- **Nunca faÃ§a commit** de PDFs de currÃ­culo/descriÃ§Ã£o de vaga (contÃ©m dados pessoais)
- Use variÃ¡veis de ambiente para todas as configuraÃ§Ãµes sensÃ­veis
- `.gitignore` estÃ¡ configurado para excluir arquivos sensÃ­veis

### ğŸ› SoluÃ§Ã£o de Problemas

#### Problemas de ConexÃ£o WebSocket

```python
# Verifique se a camada de canais estÃ¡ configurada em settings.py
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels.layers.InMemoryChannelLayer'
    }
}
```

#### Electron NÃ£o Inicia

```bash
# Reinstalar dependÃªncias do Electron
cd electron
rm -rf node_modules
npm install
npm start
```

#### Captura de Ãudio NÃ£o Funciona

- Certifique-se de que as permissÃµes do navegador foram concedidas
- Use HTTPS ou localhost (necessÃ¡rio para MediaRecorder API)
- Verifique o console do navegador para erros

### ğŸ“ LicenÃ§a

LicenÃ§a MIT - sinta-se livre para usar este projeto para fins pessoais ou comerciais.

### ğŸ‘¨â€ğŸ’» Autor

**Maikon Renner**
- GitHub: [@maikonrenner](https://github.com/maikonrenner)
- Projeto: [InterviewCo-pilot](https://github.com/maikonrenner/InterviewCo-pilot)

### â­ Apoie

Se vocÃª achar este projeto Ãºtil, considere dar uma estrela no GitHub!
